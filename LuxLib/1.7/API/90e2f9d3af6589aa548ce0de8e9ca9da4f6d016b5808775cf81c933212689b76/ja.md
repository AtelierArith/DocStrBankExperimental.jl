```
fused_conv_bias_activation(σ::F, weight::AbstractArray, x::AbstractArray,
    b::Optional{<:AbstractVector}, cdims::ConvDims) where {F}
```

`σ.(conv(x, weight, cdims) .+ b)`を計算します（`b`はこのように正確にブロードキャストされるのではなく、前の次元に合わせて形状を変更し、ブロードキャストされます）。可能な限り最良の実装を使用してこの操作を行います。この操作は、可能であれば操作を単一のカーネルに融合し、複数の操作のために出力バッファを再利用することで再割り当てを最小限に抑えます。

## 引数

  * `σ`: 活性化関数
  * `weight`: 重みテンソル
  * `x`: 入力テンソル
  * `b`: バイアステンソル（`nothing`も可能）
  * `cdims`: `ConvDims`オブジェクト

## 実装に関する注意事項

  * CUDA配列の場合、活性化が`identity`または`relu`のときに融合CUDNNカーネルを使用します。他の活性化の場合、Julia側で操作を融合しようとします。
  * 入力のいずれかがsetindexingをサポートしていない場合（すなわち不変配列）、一般的な非変異実装にフォールバックします。
  * ChainRules互換のADバックエンドまたはミューテーションをサポートするバックエンドに対しては、最大のメモリ再利用と操作の融合が保証されます。`Tracker`や`ReverseDiff`のようなバックエンドは一般的な実装にフォールバックします。
  * GPU上の混合精度入力の場合、入力を最高精度に型昇格し、警告を表示します。

```
