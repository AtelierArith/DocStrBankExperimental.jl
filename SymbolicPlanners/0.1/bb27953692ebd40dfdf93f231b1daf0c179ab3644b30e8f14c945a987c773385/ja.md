```
BoltzmannPolicy(policy, temperature, [rng::AbstractRNG])
```

指定された`temperature`に従ってボルツマン分布に基づいてアクションをサンプリングするポリシーです。状態$s$でアクション$a$を取ることの非正規化対数確率は、そのQ値$Q(s, a)$を温度$T$で割ったものに対応します：

$$
P(a|s) \propto \exp(Q(s, a) / T)
$$

温度が高いほど、ポリシーはますますランダムになりますが、温度がゼロの場合は決定論的なポリシーに対応します。Q値は、コンストラクタに引数として提供された基盤となる`policy`に従って計算されます。

既存のポリシーを`BoltzmannPolicy`でラップすることは、ベルマン方程式に従った状態値$V$とQ値$Q$の一貫性を保証しないことに注意してください。これは、収束を保証するために繰り返しベルマン更新が必要だからです。
