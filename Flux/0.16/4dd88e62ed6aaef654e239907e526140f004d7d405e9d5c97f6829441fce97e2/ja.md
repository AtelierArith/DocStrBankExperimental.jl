```
f16(m)
```

モデルの*浮動小数点*パラメータの`eltype`を`Float16`に変換します。[`@layer`](@ref Flux.@layer)でマークされた構造体に再帰します。

多くのCPUでは`Float16`のサポートが制限されています。Juliaは各操作のために`Float32`に変換する可能性があり、これは遅くなります。

他に[`f32`](@ref)および[`f64`](@ref)も参照してください。

# 例

```jldoctest
julia> m = Chain(Dense(784, 2048, relu), Dense(2048, 10))  # すべてFloat32
Chain(
  Dense(784 => 2048, relu),             # 1_607_680パラメータ
  Dense(2048 => 10),                    # 20_490パラメータ
)                   # 合計: 4配列, 1_628_170パラメータ, 6.211 MiB.

julia> m |> f16  # メモリを半分使用
Chain(
  Dense(784 => 2048, relu),             # 1_607_680パラメータ
  Dense(2048 => 10),                    # 20_490パラメータ
)                   # 合計: 4配列, 1_628_170パラメータ, 3.106 MiB.
```
