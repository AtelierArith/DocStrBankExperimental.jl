```
MDP{S,A}
```

Abstract base type for a fully observable Markov decision process.

```
S: state type
A: action type
```
