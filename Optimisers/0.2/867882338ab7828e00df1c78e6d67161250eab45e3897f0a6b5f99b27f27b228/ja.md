```
Descent(η = 1f-1)
```

古典的な勾配降下法オプティマイザで、学習率は `η` です。各パラメータ `p` とその勾配 `dp` に対して、`p -= η*dp` が実行されます。

# パラメータ

  * 学習率 (`η`): 重みを更新する前に勾配が割引かれる量。
