```
AMSGrad(η = 0.001, β = (0.9, 0.999), ϵ = 1e-8)
AMSGrad(; [eta, beta, epsilon])
```

[AMSGrad](https://openreview.net/forum?id=ryQu7f-RZ) の Adam オプティマイザのバージョン。パラメータの調整は必要ありません。

# パラメータ

  * 学習率 (`η == eta`): 勾配が重みを更新する前にどの程度割引かれるかの量。
  * モーメンタムの減衰 (`β::Tuple == beta`): 最初の (β1) および二番目の (β2) モーメンタム推定のための指数的減衰。
  * マシンイプシロン (`ϵ == epsilon`): ゼロ除算を防ぐための定数 (デフォルトを変更する必要はありません)
