```
kernel(gpu_type::Type{<:AbstractGPU}, graph::DAG, instance)
```

GPUタイプ、[`DAG`](@ref)、および問題インスタンスに対して、`compute_<id>(input::<GPU>Vector, output::<GPU>Vector, n::Int64)`というシグネチャを持つ関数を含む`Expr`を返します。これは、指定された出力ベクターに対する入力のDAG計算の結果を返すもので、GPUでの計算を目的としています。現在、`CUDAGPU`および`ROCmGPU`は、それぞれのパッケージ拡張がロードされている場合に利用可能です。

生成されたカーネル関数は、スレッドIDをx次元のみに受け入れ、ブロックIDとしてではなくスレッドIDとしてのみ受け入れます。したがって、入力と出力は1次元ベクターである必要があります。GPUプログラミングおよびJuliaパッケージに関する詳細情報については、それぞれのドキュメントを参照してください。

CUDAカーネルの簡単な呼び出し例は次のようになります：

```Julia
@cuda threads = (32,) always_inline = true cuda_kernel!(cu_inputs, outputs, length(cu_inputs))
```

!!! note
    標準の[`get_compute_function`](@ref)が`RuntimeGeneratedFunction`を返す呼び出し可能な関数を生成するのに対し、これは`eval`が必要な`Expr`を返します。これは、現在GPUカーネルをラップできない`RuntimeGeneratedFunctions.jl`の制限です。将来的には変更される可能性があります。


### サイズ制限

生成されたカーネルは内部並列化を使用せず、すなわちDAGはシリアライズされた関数にコンパイルされ、各入力をGPUの単一スレッドで処理します。これは、十分に大きな入力ベクターに対して大規模に並列化でき、GPUを100%使用できることを意味します（関数がIO制限にならないと仮定した場合）。しかし、コンパイルされた関数のサイズには限界があることも意味します。サイズが大きすぎると、コンパイルが失敗したり、完了に時間がかかりすぎたり、実行中に必要なスタックメモリが多すぎるためにカーネルが失敗したり、その他の類似の問題が発生する可能性があります。このような場合、あなたの問題はこのようなGPUカーネルにコンパイルするには大きすぎる可能性があります。

### 計算要件

GPU関数は、CPU上で実行される一般的な関数よりも計算できる内容に制限があります。Juliaでは、主に考慮すべき2つの重要な制限があります：

1. 使用されるデータ型はスタックに割り当て可能でなければならず、すなわち`isbits(x)`は`ComputeTasks`で使用される引数およびローカル変数に対して`true`でなければなりません。
2. 関数呼び出しは動的であってはなりません。これは、型の安定性が必要であり、コンパイラは事前にどのメソッドを呼び出すかを知っている必要があることを意味します。これが具体的に何を意味するかは時間とともに変わる可能性があり、異なるターゲットGPUライブラリ間でも異なります。経験から、`@cuda`呼び出しに対して`always_inline = true`引数を使用することが役立つ場合があります。

!!! warning
    この機能は現在実験的です。生成されたカーネルにはまだ解決されていない問題がいくつかあります。

