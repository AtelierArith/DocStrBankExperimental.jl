```
Descent(η = 0.1)
```

古典的な勾配降下法オプティマイザで、学習率は `η` です。各パラメータ `p` とその勾配 `δp` に対して、`p -= η*δp` を実行します。

# パラメータ

  * 学習率 (`η`): 重みを更新する前に勾配が割引かれる量。
