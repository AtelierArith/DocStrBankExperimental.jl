```
AMSGrad(η = 0.001, β::Tuple = (0.9, 0.999))
```

[AMSGrad](https://openreview.net/forum?id=ryQu7f-RZ) の ADAM オプティマイザのバージョンです。パラメータの調整は必要ありません。

# パラメータ

  * 学習率 (`η`): 勾配が重みを更新する前にどれだけ割引かれるかの量。
  * モーメンタムの減衰 (`β::Tuple`): 最初の (β1) および二番目の (β2) モーメンタム推定のための指数的減衰。

# 例

```julia
opt = AMSGrad()
opt = AMSGrad(0.001, (0.89, 0.995))
```
