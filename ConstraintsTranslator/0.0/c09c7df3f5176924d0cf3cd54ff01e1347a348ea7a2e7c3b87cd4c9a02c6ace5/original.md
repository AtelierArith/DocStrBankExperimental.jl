```
stream_completion(llm::OpenAILLM, prompt::Prompt)
```

Returns a completion for the given prompt using an OpenAI API compatible model. The completion is streamed to the terminal as it is generated.
