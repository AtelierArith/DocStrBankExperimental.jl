```
stream_completion(llm::OpenAILLM, prompt::Prompt)
```

指定されたプロンプトに対してOpenAI API互換モデルを使用して補完を返します。補完は生成されると同時にターミナルにストリーミングされます。
