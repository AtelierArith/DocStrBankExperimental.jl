```
stream_completion(llm::AbstractLLM, prompt::AbstractPrompt)
```

Returns a completion for a `prompt` using the `llm` model API. The completion is streamed to the terminal as it is generated.
