```
stream_completion(llm::AbstractLLM, prompt::AbstractPrompt)
```

`llm`モデルAPIを使用して`prompt`の完了を返します。完了は生成されると同時にターミナルにストリーミングされます。
