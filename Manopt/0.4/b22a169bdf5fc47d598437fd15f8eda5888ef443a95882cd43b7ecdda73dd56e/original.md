```
difference_of_convex_proximal_point(M, grad_h, p=rand(M); kwargs...)
difference_of_convex_proximal_point(M, mdcpo, p=rand(M); kwargs...)
```

Compute the difference of convex proximal point algorithm [SouzaOliveira:2015](@cite) to minimize

$$
    \operatorname*{arg\,min}_{p∈\mathcal M} g(p) - h(p)
$$

where you have to provide the (sub) gradient $∂h$ of $h$ and either

  * the proximal map $\operatorname{prox}_{\lambda g}$ of `g` as a function `prox_g(M, λ, p)` or  `prox_g(M, q, λ, p)`
  * the functions `g` and `grad_g` to compute the proximal map using a sub solver
  * your own sub-solver, see optional keywords below

This algorithm performs the following steps given a start point `p`= $p^{(0)}$. Then repeat for $k=0,1,\ldots$

1. $X^{(k)}  ∈ \operatorname{grad} h(p^{(k)})$
2. $q^{(k)} = \operatorname{retr}_{p^{(k)}}(λ_kX^{(k)})$
3. $r^{(k)} = \operatorname{prox}_{λ_kg}(q^{(k)})$
4. $X^{(k)} = \operatorname{retr}^{-1}_{p^{(k)}}(r^{(k)})$
5. Compute a stepsize $s_k$ and
6. set $p^{(k+1)} = \operatorname{retr}_{p^{(k)}}(s_kX^{(k)})$.

until the `stopping_criterion` is fulfilled. See [AlmeidaNetoOliveiraSouza:2020](@cite) for more details on the modified variant, where steps 4-6 are slightly changed, since here the classical proximal point method for DC functions is obtained for $s_k = 1$ and one can hence employ usual line search method.

# Optional parameters

  * `λ`:                          ( `i -> 1/2` ) a function returning the sequence of prox parameters λi
  * `evaluation`:                 ([`AllocatingEvaluation`](@ref)) specify whether the gradient works by allocation (default) form `gradF(M, x)` or [`InplaceEvaluation`](@ref) in place of the form `gradF!(M, X, x)`.
  * `cost`:                       (`nothing`) provide the cost `f`, for debug reasons / analysis the default `sub_problem`. Use this if you have a more efficient version than using `g` from before.
  * `gradient`:                   (`nothing`) specify $\operatorname{grad} f$, for debug / analysis  or enhancing the `stopping_criterion`
  * `prox_g`:                     (`nothing`) specify a proximal map for the sub problem *or* both of the following
  * `g`:                          (`nothing`) specify the function `g`.
  * `grad_g`:                     (`nothing`) specify the gradient of `g`. If both `g`and `grad_g` are specified, a subsolver is automatically set up.
  * `inverse_retraction_method`:  (`default_inverse_retraction_method(M)`) an inverse retraction method to use (see step 4).
  * `retraction_method`:          (`default_retraction_method(M)`) a retraction to use (see step 2)
  * `stepsize`:                   ([`ConstantStepsize`](@ref)`(M)`) specify a [`Stepsize`](@ref) to run the modified algorithm (experimental.) functor.
  * `stopping_criterion`:         ([`StopAfterIteration`](@ref)`(200) |`[`StopWhenChangeLess`](@ref)`(1e-8)`) a [`StoppingCriterion`](@ref) for the algorithm, also includes a [`StopWhenGradientNormLess`](@ref)`(1e-8)`, when a `gradient` is provided.

While there are several parameters for a sub solver, the easiest is to provide the function `g` and `grad_g`, such that together with the mandatory function `g` a default cost and gradient can be generated and passed to a default subsolver. Hence the easiest example call looks like

```
difference_of_convex_proximal_point(M, grad_h, p0; g=g, grad_g=grad_g)
```

# Optional parameters for the sub problem

  * `sub_cost`:               ([`ProximalDCCost`](@ref)`(g, copy(M, p), λ(1))`) cost to be used within the default `sub_problem` that is initialized as soon as `g` is provided.
  * `sub_grad`:               ([`ProximalDCGrad`](@ref)`(grad_g, copy(M, p), λ(1); evaluation=evaluation)` gradient to be used within the default `sub_problem`, that is initialized as soon as `grad_g` is provided. This is generated by default when `grad_g` is provided. You can specify your own by overwriting this keyword.
  * `sub_hess`:               (a finite difference approximation by default) specify a Hessian of the subproblem, which the default solver, see `sub_state` needs
  * `sub_kwargs`:             (`(;)`) pass keyword arguments to the `sub_state`, in form of a `Dict(:kwname=>value)`, unless you set the `sub_state` directly.
  * `sub_objective`:          (a gradient or Hessian objective based on the last 3 keywords) provide the objective used within `sub_problem` (if that is not specified by the user)
  * `sub_problem`:            ([`DefaultManoptProblem`](@ref)`(M, sub_objective)` specify a manopt problem for the sub-solver runs. You can also provide a function for a closed form solution. Then `evaluation=` is taken into account for the form of this function.
  * `sub_state`:              ([`TrustRegionsState`](@ref)). requires the `sub_Hessian to be provided,  decorated with`sub*kwargs`) choose the solver by specifying a solver state to solve the`sub*problem`
  * `sub_stopping_criterion`: ([`StopAfterIteration`](@ref)`(300) |`[`StopWhenStepsizeLess`](@ref)`(1e-9) |`[`StopWhenGradientNormLess`](@ref)`(1e-9)`) a stopping criterion used withing the default `sub_state=`

all others are passed on to decorate the inner [`DifferenceOfConvexProximalState`](@ref).

# Output

the obtained (approximate) minimizer $p^*$, see [`get_solver_return`](@ref) for details
