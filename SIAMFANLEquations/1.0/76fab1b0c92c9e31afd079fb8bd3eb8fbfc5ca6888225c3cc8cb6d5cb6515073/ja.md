```
nsol(F!, x0, FS, FPS, J!=diffjac!; rtol=1.e-6, atol=1.e-12,
           maxit=20, solver="newton", sham=5, armmax=10, resdec=.1,
           dx = 1.e-7, armfix=false, 
           pdata = nothing, jfact = klfact,
           printerr = true, keepsolhist = false, stagnationok=false)
```

C. T. Kelley, 2022

私のSIAMの本からの非線形ソルバーのJuliaバージョン。ここに：nsol

関数とヤコビ行列のストレージを事前に割り当てる必要があります –> 呼び出しプログラム内で <– つまり、FSとFPSで

入力：

  * F!: 関数評価、!はF!がFSを上書きすることを示し、これは関数のための事前に割り当てられたストレージです。

    したがって、FS=F!(FS,x)またはFS=F!(FS,x,pdata)はFS=F(x)を返します。

    あなたの関数は必ず –> FSを返す <– 必要があります。ドキュメントの例やTestProblems/Systems/simple.jlを参照してください。
  * x0: 初期反復値
  * FS: 関数のための事前に割り当てられたストレージ。サイズNのベクトルです。

    (N)として保存し、F!をサイズ(N)のベクトルを使用するように設計する必要があります。(N,1)を一貫して使用する場合、ソルバーは動作するかもしれませんが、保証はしません。
  * FPS: ヤコビ行列のための事前に割り当てられたストレージ。N x Nの行列です。
  * J!: ヤコビ行列評価、!はJ!がFPSを上書きすることを示し、これはヤコビ行列のための事前に割り当てられたストレージです。これを省略すると、デフォルトは有限差分ヤコビ行列です。

    したがって、FP=J!(FP,FS,x)またはFP=J!(FP,FS,x,pdata)はFP=F'(x)を返します。

    (FP,FS,x)は引数リストでなければなりません。たとえFPがFSを必要としなくても。これは、有限差分ヤコビ行列が必要であり、これはソルバーのデフォルトです。

    あなたのヤコビ行列関数は必ず –> FPを返す <– 必要があります。ドキュメントの例やTestProblems/Systems/simple.jlを参照してください。
  * 精度：精度についてお話ししましょう。このコードは、あなたが望む任意の精度で完全精度の関数と線形代数のために設計しました。FPSをFloat64、Float32、またはFloat16として宣言することができ、nsolはあなたがJ!関数内で宣言を破壊しない限り、正しいことを行います。これがこんなに簡単に機能することに驚いています。ヤコビ行列が適切に条件付けられている場合、ヤコビ行列の因子化とストレージのコストを半分に削減できます。大きな密なヤコビ行列と安価な関数の場合、これは良い取引です。

    しかし... Float64以外の直接スパースソルバーに対するサポートは非常に限られています。あなたが本当に何をしているのかを知っていない限り、直接スパースソルバーにはFloat64のみを使用することをお勧めします。ノートブックにいくつかの例がありますが、注意してください。

---

キーワード引数 (kwargs):

rtolおよびatol：相対および絶対誤差許容値

maxit：非線形反復の制限

solver：デフォルト = "newton"

あなたの選択肢は "newton" または "chord" です。ただし、newtonを選択した場合にのみshamを使用できます。"chord"は、反復が収束するまで初期導関数を使用し、反復予算を使用するか、ラインサーチが失敗するまで使用します。これはsham=Infとは異なり、こちらの方が賢いです。

sham：デフォルト = 5（つまりニュートン）

これはシャマンスキー法です。sham=1の場合、ニュートンがあります。反復はsham回ごとに導関数を更新します。収束率は、導関数を更新する反復のみをカウントする場合、局所q-次数sham+1になります。このオプションを使用するために独自の導関数関数を提供する必要はありません。sham=Infは、chordがうまく収束している場合にのみchordです。

スカラー方程式のデフォルトとしてsham=1を設定しました。システムの場合、私はより攻撃的で、線形代数にできるだけ少ないエネルギーを投資したいと考えています。したがって、デフォルトはsham=5です。

armmax：ラインサーチにおけるステップサイズの減少の上限

resdec：デフォルト = .1

これは残差削減の目標値です。デフォルト値は.1です。古いMATLABコードでは.5でした。残差が急速に減少している場合、少なくともresdecの因子で、ラインサーチが静止している場合にのみシャマンスキーをオンにします。このメソッドからresdecを排除したい場合（したくないですが）、resdec = 1.0に設定すると、二度と聞くことはありません。

dx：デフォルト = 1.e-7

有限差分導関数における差分増分 h=dx*norm(x,Inf)+1.e-8

armfix：デフォルト = false

デフォルトは放物線ラインサーチ（つまりfalse）です。trueに設定すると、ステップサイズは.5に固定されます。研究のための実験を行っている場合を除いて、これを行わないでください。

pdata：

関数/ヤコビ行列のための事前計算されたデータ。関数/ヤコビ行列内のグローバル変数にデータを隠すよりも、これを使用した方がうまくいきます。

F!またはJ!のいずれかでpdataを使用する場合、両方の呼び出しシーケンスで使用する必要があります。

jfact：デフォルト = klfact（最適な選択を見つけようとします）

ヤコビ行列に特別な構造がある場合は、因子化のための正しい選択にjfactを設定してください。

私はPrepareJac!を呼び出してヤコビ行列を評価（あなたのJ!を使用）し、因子化する際にjfactを使用します。デフォルトは、klfact（内部関数）を使用して合理的なことを行うことです。一般的な密な行列の場合、klfactはlu!を選択してLU因子化を計算し、ヤコビ行列とストレージを共有します。たとえば、ヤコビ行列がspdの場合、jfact = cholesky!に設定することでLUを別のものに変更できます。

klfactはバンド行列について知っており、qrを選択します。ただし、RTFMを行い、追加の2つの上部バンドを割り当て、jfact=qr!を使用してklfactをオーバーライドする必要があります。

klfactは一般的なスパース行列にluを使用します。

klfactがディスパッチ方法を知らないものを与えた場合、何も起こりません。私は元のヤコビ行列を返し、nsolはニュートンステップを計算するためにバックスラッシュを使用します。これはおそらくあなたの状況では最適ではないので、jfact = luのように他の何かを選択するのが良いです。

ヤコビ行列評価関数内で独自の因子化を管理したい場合は、次のように設定します。

jfact = nofact

そうすれば、nsolはヤコビ行列を因子化しようとはしません。klfactが何をすべきかを知らない場合も同様です。あなたのヤコビ行列はJuliaの\操作に直接送られます。

PrepareJac!を呼び出す行をいじらないでください。

```
    FPF = PrepareJac!(FPS, FS, x, ItRules)
```

FPFは理由があってFPS（ヤコビ行列のために割り当てたストレージ）とは異なります。FPFとFPSは同じ型ではありませんが、ストレージを共有しています。したがって、FPS=PrepareJac!(FPS, FS, ...)は物事を壊します。

printerr：デフォルト = true

ソルバーが失敗したときに役立つメッセージを印刷します。そのメッセージを抑制するには、printerrをfalseに設定します。

keepsolhist：デフォルト = false

出力タプルに反復の履歴を取得するには、これをtrueに設定します。これはスカラー方程式のデフォルトでオンになっており、システムではオフになっています。データに使用する必要がある場合にのみオンにしてください。これは非常に大きくなる可能性があります。

stagnationok：デフォルト = false

ラインサーチを無効にし、発散または停滞を観察したい場合は、これをtrueに設定します。これは研究や本を書くためにのみ役立ちます。

出力：

  * 名前付きタプル (solution, functionval, history, stats, idid, errcode, solhist)

ここで

– solution = 収束した結果

– functionval = F(solution)

– history = 反復の残差ノルムのベクトル (||F(x)||)

– stats = (ifun, ijac, iarm)の履歴の名前付きタプル、各反復での関数/導関数/ステップ長の減少の数。

有限差分導関数の関数値はヤコビ行列評価にカウントされるため、カウントしません。

– idid=trueは反復が成功した場合、falseはそうでない場合。

– errcode = 0は反復が成功した場合

```
    = -1は初期反復値が終了基準を満たす場合

    = 10はmaxit反復後に収束しない場合

    = 1はラインサーチが失敗した場合
```

– solhist：

keepsolhist=trueに設定した場合、これは反復の全履歴です。

solhistはN x Kの配列で、Nはxの長さ、Kは反復の数+1です。したがって、スカラー方程式の場合、これは行ベクトルです。

---

### nsolの例

#### 世界で最も簡単な問題の例。

64ビットと32ビットのヤコビ行列をテストします。残差履歴や収束した解に意味のある違いはありません。

```jldoctest
 julia> function f!(fv,x)
       fv[1]=x[1] + sin(x[2])
       fv[2]=cos(x[1]+x[2])
#
# return fv部分は重要です。f!がfvを上書きしても。
#
       return fv
       end
f (generic function with 1 method)

julia> x=ones(2); fv=zeros(2); jv=zeros(2,2); jv32=zeros(Float32,2,2);
julia> nout=nsol(f!,x,fv,jv; sham=1);
julia> nout32=nsol(f!,x,fv,jv32; sham=1);
julia> [nout.history nout32.history]
5×2 Matrix{Float64}:
 1.88791e+00  1.88791e+00
 2.43119e-01  2.43120e-01
 1.19231e-02  1.19231e-02
 1.03266e-05  1.03265e-05
 1.46388e-11  1.45995e-11

julia> [nout.solution nout.solution-nout32.solution]
2×2 Array{Float64,2}:
 -7.39085e-01  -5.48450e-14
  2.30988e+00  -2.26485e-14
```

#### H方程式の例。

ここではデフォルトのsham=5を使用しているため、収束は二次的ではありません。良いニュースは、ヤコビ行列を1回だけ評価することです。

```jldoctest
julia> n=16; x0=ones(n); FV=ones(n); JV=ones(n,n);
julia> hdata=heqinit(x0, .5);
julia> hout=nsol(heqf!,x0,FV,JV;pdata=hdata);
julia> hout.history
4-element Array{Float64,1}:
 6.17376e-01
 3.17810e-03
 2.75227e-05
 2.35817e-07
```
