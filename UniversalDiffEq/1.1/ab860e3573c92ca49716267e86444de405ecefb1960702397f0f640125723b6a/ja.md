train!(UDE::UDE; kwargs...)

この関数は、UDEモデルのためのいくつかのトレーニングルーチンへのアクセスを提供します。ユーザーはUDEモデルオブジェクトを提供し、キーワード引数を使用していくつかの損失関数と最適化アルゴリズムの中から選択できます。トレーニングルーチンは、トレーニングされたパラメータでUDEオブジェクトを更新し、トレーニング手順中に推定された他の有用な量を返します。デフォルトのオプティマイザは、`maxiter`ステップのサイズ`step_size`を使用して損失関数を最小化することによってUDEモデルをトレーニングします。`loss_function`引数を使用して、条件付き尤度、周辺尤度、導関数マッチング、シューティング、および複数シューティングの5つの損失関数が利用可能です。`loss_options`および`optim_options`引数は、トレーニングルーチンにパラメータを渡すために使用できる名前付きタプルです。

# kwargs

  * `loss_function`: モデルをトレーニングするために使用される損失関数を決定し、効率のためにデフォルトは「導関数マッチング」です。
  * `verbose`: trueの場合、オプティマイザの各ステップの間に損失関数の値が印刷されます。
  * `regularization_weight`: 損失関数における正則化に与えられる重み。デフォルトは0です。
  * `optimizer`: モデルをトレーニングするために使用される最適化アルゴリズムを決定し、デフォルトは勾配降下法の「ADAM」です。
  * `loss_options`: 損失関数を構築するのに役立つキーワード引数を持つ名前付きタプル。
  * `optim_options`: 最適化アルゴリズムに渡すためのキーワード引数を持つ名前付きタプル。ADAMの場合、これらは`maxiter`（アルゴリズムを実行するために使用される反復回数）と`step_size`（各反復のサイズ）です。

# 損失関数

ユーザーは、条件付き尤度、周辺尤度、導関数マッチング、シューティング、および複数シューティングの5つの損失関数のいずれかを選択できます。

|      損失関数 | 離散モデル | 連続モデル |  速度 |
| ---------:| -----:| -----:| ---:|
|    条件付き尤度 |    はい |    はい | 中程度 |
|      周辺尤度 |    はい |    はい |  遅い |
|  導関数マッチング |   いいえ |    はい |  速い |
|   シューティング |   いいえ |    はい | 中程度 |
| 複数シューティング |   いいえ |    はい | 中程度 |

## 条件付き尤度:

条件付き尤度を使用するには、キーワード引数`loss_function = "conditional likelihood"`を設定します。

このオプションは、UDEがプロセスモデルとして使用される状態空間モデルの条件付き尤度を最大化することによって、不完全な観測とプロセスの不確実性を考慮しながらUDEモデルをトレーニングします。条件付き尤度は計算が速いですが、周辺尤度よりも精度が低い場合があります。

## 周辺尤度:

周辺尤度を使用するには、キーワード引数`loss_function = "marginal likelihood"`を設定します。

このオプションは、無香料カルマンフィルタを使用して近似される状態空間モデルの周辺尤度を最大化します。このオプションは条件付き尤度よりも遅いですが、理論的にはトレーニングされたモデルの精度を向上させるはずです（すなわち、バイアスを減少させる）。

### loss_options

  * `process_error`: プロセスエラーのレベルの初期推定。デフォルトは0.1です。
  * `observation_error`: データセットにおける観測エラーのレベル。デフォルトはないため、提供されない場合はエラーが発生します。
  * `α`: カルマンフィルタアルゴリズムのパラメータ。デフォルトは10^-3です。
  * `β`: カルマンフィルタアルゴリズムのパラメータ。デフォルトは2です。
  * `κ`: カルマンフィルタアルゴリズムのパラメータ。デフォルトは0です。

## 導関数マッチング:

導関数マッチングトレーニングルーチンを使用するには、`loss_function = "derivative matching"`を設定します。

この関数は、UDEモデルを2段階のプロセスでトレーニングします。最初に、スプライン回帰を使用してデータにフィットするスムージング関数を適合させます。次に、スムージング関数の導関数とUDEの右辺によって予測された導関数を比較することによってUDEモデルをトレーニングします。このトレーニングルーチンは代替手段よりもはるかに速いですが、精度が低い場合があります。

### loss_options

  * `d`: 曲線フィッティング関数の自由度の数。デフォルトは12です。
  * `alg`: データセットに曲線をフィットさせるために使用されるアルゴリズム。詳細についてはDataInterpolationsパッケージを参照してください。デフォルトは一般化交差検証`：gcv_svd`です。
  * `remove_ends`: UDEをトレーニングする際に曲線フィッティングプロセスからのエッジ効果を減少させるためにデータセットの端から外すデータポイントの数。デフォルトは0です。

## シューティング:

シューティングトレーニングルーチンを使用するには、`loss_function = "shooting"`を設定します。

このオプションは、初期データポイントから最終データポイントまでのODEを解くことによって損失を計算し、観測された軌道と予測された軌道を平均二乗誤差（MSE）で比較します。初期データポイントは観測エラーの影響を減少させるために自由パラメータとして推定されます。

## 複数シューティング:

複数シューティングトレーニングルーチンを使用するには、`loss_function = "multiple shooting"`を設定します。

このオプションは、データを連続観測のブロックに分割することによって損失を計算します。次に、UDEを使用して各ブロックの初期データポイントから次のブロックの最初のデータポイントまで予測します。損失は、予測とデータポイントの間のMSEとして定義されます。各ブロックの初期データポイントは観測エラーの影響を減少させるために自由パラメータとして推定されます。

### loss_options

  * `pred_length`: 各ブロックのデータポイントの数。デフォルトは10です。

# 最適化アルゴリズム

損失関数を最小化するために使用される方法。2つのオプションがあります：ADAMとBFGS。ADAMは一次勾配降下アルゴリズムであり、BFGSは近似二次情報を使用する準ニュートン法です。

ユーザーは、`optim_options`キーワード引数を使用して各アルゴリズムの最大反復回数`maxiter`を指定できます。ADAMの場合、`optim_options`を使用してステップサイズ`step_size`を指定でき、BFGSの場合は初期ステップノルム`initial_step_norm`を指定できます。
