```
(flux::NeuralFlux)(input::AbstractArray, params::ComponentVector; kwargs...)
```

入力データに対して水のフラックスを計算するためのニューラルネットワークベースのフラックスモデルを適用します。

# 引数

  * `input::AbstractArray`: 次の可能な次元を持つ入力データ配列：

      * `Matrix`: 形状が (変数, タイムステップ) の時系列データ
      * `Array{3}`: 形状が (変数, ノード, タイムステップ) の分散データ
  * `params::ComponentVector`: ニューラルネットワークの重みとバイアスを含むモデルパラメータ
  * `kwargs`: 追加のキーワード引数：

      * `ptyidx::AbstractVector{Int}`: 分散実行のためのパラメータタイプインデックス（デフォルト：すべてのノード）

# 戻り値

  * `Matrix`: 2D入力の場合、形状が (出力変数, タイムステップ) の行列を返します
  * `Array{3}`: 3D入力の場合、形状が (出力変数, ノード, タイムステップ) の配列を返します

# 説明

この関数は、入力時系列データに対してニューラルネットワークベースのフラックス計算を適用し、単一ノードおよび分散（マルチノード）シミュレーションの両方をサポートします。ニューラルネットワークのパラメータは、パラメータベクトルの適切なコンポーネントから自動的に取得されます。

## 入力データ構造

  * 変数は最初の次元に沿って配置する必要があります
  * 分散実行の場合、ノードは2番目の次元に沿っています
  * タイムステップは常に最後の次元にあります

## パラメータ処理

  * ニューラルネットワークのパラメータは `params[:nns][chain_name]` を介してアクセスされます
  * パラメータはニューラルネットワークで定義された構造を維持します
  * 分散実行の場合、同じネットワークが各ノードに適用されます

## 例

```julia
# ニューラルネットワークフラックスを定義
flux = NeuralFlux(
    [P, E] => [Q],           # 入力/出力構造
    Dense(2, 1, tanh)        # ニューラルネットワークアーキテクチャ
)

# 単一ノードシミュレーション
output = flux(input, params)  # input: (2, タイムステップ)

# マルチノードシミュレーション
output = flux(input, params)  # input: (2, n_nodes, タイムステップ)
```

# 注意事項

  * ニューラルネットワークのパラメータは使用前に適切に初期化する必要があります
  * ニューラルネットワークのアーキテクチャは入力/出力の次元と一致する必要があります
  * 分散実行の場合、同じネットワークがすべてのノードで共有されます
