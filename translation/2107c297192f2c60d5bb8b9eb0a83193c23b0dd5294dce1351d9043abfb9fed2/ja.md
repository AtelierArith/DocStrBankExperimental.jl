# Parallel Computing

Juliaは、次の4つの並行および並列プログラミングのカテゴリをサポートしています：

1. **非同期の「タスク」、またはコルーチン**:

    Juliaのタスクは、I/O、イベント処理、プロデューサー-コンシューマーのプロセス、および同様のパターンのために計算を一時停止および再開することを可能にします。タスクは、[`wait`](@ref)や[`fetch`](@ref)のような操作を通じて同期することができ、[`Channel`](@ref)を介して通信します。厳密には自体で並列計算ではありませんが、Juliaは複数のスレッドで[`Task`](@ref)をスケジュールすることを許可します。
2. **マルチスレッド**:

    ジュリアの [multi-threading](@ref man-multithreading) は、複数のスレッドまたはCPUコアでタスクを同時にスケジュールする能力を提供し、メモリを共有します。これは通常、PCや単一の大規模マルチコアサーバーで並列処理を得る最も簡単な方法です。ジュリアのマルチスレッドは合成可能です。あるマルチスレッド関数が別のマルチスレッド関数を呼び出すと、ジュリアは利用可能なリソース上で全てのスレッドをグローバルにスケジュールし、オーバーサブスクリプションを避けます。
3. **分散コンピューティング**:

    分散コンピューティングは、別々のメモリ空間を持つ複数のJuliaプロセスを実行します。これらは同じコンピュータ上または複数のコンピュータ上で実行できます。[`Distributed`](@ref man-distributed)標準ライブラリは、Julia関数のリモート実行の機能を提供します。この基本的なビルディングブロックを使用することで、さまざまな種類の分散コンピューティング抽象を構築することが可能です。[`DistributedArrays.jl`](https://github.com/JuliaParallel/DistributedArrays.jl)のようなパッケージは、そのような抽象の一例です。一方、[`MPI.jl`](https://github.com/JuliaParallel/MPI.jl)や[`Elemental.jl`](https://github.com/JuliaParallel/Elemental.jl)のようなパッケージは、既存のMPIエコシステムのライブラリへのアクセスを提供します。
4. **GPUコンピューティング**:

    Julia GPUコンパイラは、GPU上でJuliaコードをネイティブに実行する機能を提供します。GPUをターゲットにしたJuliaパッケージの豊富なエコシステムがあります。[JuliaGPU.org](https://juliagpu.org)ウェブサイトでは、機能、サポートされているGPU、関連パッケージおよびドキュメントのリストが提供されています。
